<Type Name="SpeechDetectedEventArgs" FullName="System.Speech.Recognition.SpeechDetectedEventArgs">
  <TypeSignature Language="C#" Value="public class SpeechDetectedEventArgs : EventArgs" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit SpeechDetectedEventArgs extends System.EventArgs" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.SpeechDetectedEventArgs" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.EventArgs</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>データを返す<see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected" />または<see cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />イベント。</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 A`SpeechDetected`によってイベントが発生した、<xref:System.Speech.Recognition.SpeechRecognizer>と<xref:System.Speech.Recognition.SpeechRecognitionEngine>クラスです。  
  
 **SpeechDetected**認識エンジンは、人間の音声としてオーディオ入力を識別できる場合にイベントが生成されます。  
  
 <xref:System.Speech.Recognition.SpeechDetectedEventArgs> は、<xref:System.EventArgs> から派生します。  
  
   
  
## Examples  
 次の例のハンドラーを作成する<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected?displayProperty=nameWithType>または<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected?displayProperty=nameWithType>イベント。 ハンドラーは、音声が検出され、オーディオの位置を含む、状態情報を表示するたびに、表示を初期化します。  
  
```  
_recognizer.SpeechDetected +=  
  delegate(object sender, SpeechDetectedEventArgs eventArgs)   
  {  
  
    // Clear previous recognition information.  
    _audioDeviceStatusLabel.Enabled = true;  
    _audioDeviceStatusLabel.Visible = true;  
    Utils.DisplayAudioInputFormat(_audioStateLabel, _recognizer);  
    Utils.DisplayRecognizerState(_recognizerStateLabel, _recognizer.State);  
    Utils.DisplaySpeechDetected(_speechDetectedLabel, eventArgs.AudioPosition);  
  };  
```  
  
 ]]></format>
    </remarks>
  </Docs>
  <Members>
    <Member MemberName="AudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan AudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan AudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>音声が検出されたオーディオ ストリーム内の位置を取得します。</summary>
        <value>認識エンジンの音声バッファー内にある検出されたフレーズの場所を返します。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 次の例のハンドラーを作成する<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected?displayProperty=nameWithType>または<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected?displayProperty=nameWithType>イベント。 ハンドラーは、各時間音声が検出され、オーディオの位置を含む、状態情報を表示、表示を初期化します。  
  
```  
_recognizer.SpeechDetected +=  
  delegate(object sender, SpeechDetectedEventArgs eventArgs)   
  {  
  
    // Clear previous recognition information.  
    _audioDeviceStatusLabel.Enabled = true;  
    _audioDeviceStatusLabel.Visible = true;  
    Utils.DisplayAudioInputFormat(_audioStateLabel, _recognizer);  
    Utils.DisplayRecognizerState(_recognizerStateLabel, _recognizer.State);  
    Utils.DisplaySpeechDetected(_speechDetectedLabel, eventArgs.AudioPosition);  
  };  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
  </Members>
</Type>
